{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from google import genai\n",
        "\n",
        "# --- Load knowledge base ---\n",
        "with open(\"knowledge.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"This is a sample Arduino knowledge base. Replace this with your real file!\")\n",
        "\n",
        "with open(\"knowledge.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    knowledge_base = f.read()\n",
        "\n",
        "# --- Mock secrets for Colab ---\n",
        "st.secrets[\"GEMINI_API_KEY\"] = \"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\"\n",
        "\n",
        "# --- Session state ---\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = [\n",
        "        {\"role\": \"system\", \"content\": \"üëã Welcome to Arduino Expert! Ask me anything about Arduino projects.\"}\n",
        "    ]\n",
        "\n",
        "def chat(user_input):\n",
        "    global knowledge_base\n",
        "    api_key = st.secrets[\"GEMINI_API_KEY\"]\n",
        "\n",
        "    if not api_key:\n",
        "        return \"‚ö†Ô∏è Please set your Gemini API key.\"\n",
        "\n",
        "    context_text = f\"Knowledge base:\\n{knowledge_base}\\n\\n\"\n",
        "    for msg in st.session_state.chat_history:\n",
        "        context_text += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n",
        "    context_text += f\"User: {user_input}\\nAnswer based on the knowledge above.\"\n",
        "\n",
        "    try:\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        chat_session = client.chats.create(model=\"gemini-2.5-flash\")\n",
        "        response = chat_session.send_message(context_text)\n",
        "        reply = response.text\n",
        "    except Exception as e:\n",
        "        reply = f\"‚ùå Error: {e}\"\n",
        "\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return reply\n",
        "\n",
        "st.set_page_config(page_title=\"Arduino Expert\", page_icon=\"ü§ñ\")\n",
        "\n",
        "st.markdown(\"<h2 style='text-align:center;color:#0082C9;'>ü§ñ Arduino Expert Chatbot</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "for msg in st.session_state.chat_history:\n",
        "    if msg[\"role\"] == \"user\":\n",
        "        st.chat_message(\"user\").markdown(msg[\"content\"])\n",
        "    elif msg[\"role\"] == \"assistant\":\n",
        "        st.chat_message(\"assistant\").markdown(msg[\"content\"])\n",
        "    elif msg[\"role\"] == \"system\":\n",
        "        st.chat_message(\"system\").markdown(msg[\"content\"])\n",
        "\n",
        "user_input = st.chat_input(\"Ask a question...\")\n",
        "if user_input:\n",
        "    reply = chat(user_input)\n",
        "    st.chat_message(\"assistant\").markdown(reply)\n",
        "\n",
        "if st.button(\"üßπ Clear Chat\"):\n",
        "    st.session_state.chat_history = [\n",
        "        {\"role\": \"system\", \"content\": \"üëã Welcome to Arduino Expert! Ask me anything about Arduino projects.\"}\n",
        "    ]\n",
        "    st.experimental_rerun()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HqPH34IvXq3",
        "outputId": "be3b759e-2865-449a-a444-6e0895a8e089"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}